{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32c50ee0",
   "metadata": {},
   "source": [
    "# Late Blight Risk Prediction - Google Colab Notebook\n",
    "This notebook loads and prepares your dataset, applies SMOTE to address class imbalance, trains a Random Forest model, and evaluates its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39008b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a52c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"Libraries imported successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faea853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csv_filename = \"Lateblight_Data_UNIQUE_Planting_Months.csv\"\n",
    "try:\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    print(f\"Dataset '{csv_filename}' loaded successfully. First 5 rows:\")\n",
    "    display(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File '{csv_filename}' not found. Please upload it to the Colab session.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6ea2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'df' in locals():\n",
    "    columns_to_drop = [\"Date\", \"Variety_Notes\", \"Environmental_Impact\", \"Planting_Months\"]\n",
    "    df = df.drop(columns=columns_to_drop, errors='ignore')\n",
    "    print(f\"Dropped columns (if they existed): {columns_to_drop}\")\n",
    "    original_rows = len(df)\n",
    "    df = df.dropna(subset=[\"Blight_Risk\"])\n",
    "    rows_after_na_drop = len(df)\n",
    "    print(f\"Dropped {original_rows - rows_after_na_drop} rows with missing 'Blight_Risk'.\")\n",
    "    print(\"\\nRemaining columns:\", list(df.columns))\n",
    "    print(f\"Dataset shape after cleaning: {df.shape}\")\n",
    "else:\n",
    "    print(\"Skipping data cleaning as DataFrame 'df' was not loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7870ceb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'df' in locals():\n",
    "    label_encoder = LabelEncoder()\n",
    "    df[\"Blight_Risk_Encoded\"] = label_encoder.fit_transform(df[\"Blight_Risk\"])\n",
    "    print(\"Target variable 'Blight_Risk' encoded into 'Blight_Risk_Encoded'.\")\n",
    "    print(\"Mapping:\", dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))))\n",
    "    X = pd.get_dummies(df.drop(columns=[\"Blight_Risk\", \"Blight_Risk_Encoded\"]))\n",
    "    y = df[\"Blight_Risk_Encoded\"]\n",
    "    print(\"\\nFeatures prepared (One-Hot Encoded). Shape of X:\", X.shape)\n",
    "    print(\"Target prepared. Shape of y:\", y.shape)\n",
    "    print(\"\\nFeature columns after One-Hot Encoding (first 15 shown):\")\n",
    "    print(list(X.columns[:15]))\n",
    "else:\n",
    "    print(\"Skipping encoding as DataFrame 'df' was not loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24ff1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'X' in locals() and 'y' in locals():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    print(\"Data split into training and testing sets.\")\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"X_test shape:\", X_test.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "    print(\"y_test shape:\", y_test.shape)\n",
    "    print(\"\\nOriginal class distribution in y_train (counts):\")\n",
    "    print(y_train.value_counts())\n",
    "    print(\"\\nOriginal class distribution in y_train (proportions):\")\n",
    "    print(y_train.value_counts(normalize=True))\n",
    "    print(\"\\nOriginal class distribution in y_test (counts):\")\n",
    "    print(y_test.value_counts())\n",
    "else:\n",
    "    print(\"Skipping Train/Test split as X and y were not defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6082731",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'X_train' in locals() and 'y_train' in locals():\n",
    "    min_samples = y_train.value_counts().min()\n",
    "    print(f\"\\nSmallest class in y_train has {min_samples} samples.\")\n",
    "    smote_k_neighbors = min(5, min_samples - 1)\n",
    "    if smote_k_neighbors < 1:\n",
    "        print(\"Warning: Minority class has only 1 sample. Cannot apply SMOTE with k>0.\")\n",
    "        X_train_res, y_train_res = X_train, y_train\n",
    "    else:\n",
    "        print(f\"Applying SMOTE with k_neighbors = {smote_k_neighbors}\")\n",
    "        smote = SMOTE(random_state=42, k_neighbors=smote_k_neighbors)\n",
    "        X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "        print(\"SMOTE applied successfully to the training data.\")\n",
    "    print(\"\\nX_train_res shape:\", X_train_res.shape)\n",
    "    print(\"y_train_res shape:\", y_train_res.shape)\n",
    "    print(\"\\nClass distribution in y_train_res (after SMOTE):\")\n",
    "    print(pd.Series(y_train_res).value_counts())\n",
    "    print(pd.Series(y_train_res).value_counts(normalize=True))\n",
    "else:\n",
    "    print(\"Skipping SMOTE as X_train and y_train were not defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04824610",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'X_train_res' in locals() and 'y_train_res' in locals():\n",
    "    model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    print(\"Random Forest model trained successfully.\")\n",
    "else:\n",
    "    print(\"Skipping model training as resampled training data is not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc883f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'model' in locals() and 'X_test' in locals() and 'y_test' in locals():\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"\\nClassification Report (on Test Set):\")\n",
    "    if 'label_encoder' in locals():\n",
    "        print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "        print(\"\\nConfusion Matrix (on Test Set):\")\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        cm_df = pd.DataFrame(cm, index=label_encoder.classes_, columns=label_encoder.classes_)\n",
    "        display(cm_df)\n",
    "    else:\n",
    "        print(\"LabelEncoder not found. Cannot display class names in report/matrix.\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(\"\\nConfusion Matrix (numeric labels):\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "else:\n",
    "    print(\"Skipping model evaluation as model or test data is not available.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
